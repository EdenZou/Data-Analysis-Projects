{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import jieba\n",
    "import math\n",
    "import numpy as np\n",
    "import jieba.posseg as psg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "infile1=open('../data/现代汉语通用字表（笔画+偏旁部首）.csv','r',encoding='utf-8')\n",
    "to_read1=csv.reader(infile1)\n",
    "lst1=[]\n",
    "\n",
    "for row in to_read1:\n",
    "    lst1.append(row) # a list of characters and their strokes\n",
    "    \n",
    "old_str1=lst1[0][0]\n",
    "new_str1=old_str[-1]\n",
    "lst1[0][0]=new_str1\n",
    "\n",
    "char_list1=[]\n",
    "stroke_list1=[]\n",
    "\n",
    "for i in range(len(lst1)):\n",
    "    char_list1.append(lst1[i][0])\n",
    "    stroke_list1.append(lst1[i][1])\n",
    "\n",
    "def stroke_complexity_score(sen,char_list,stroke_list):\n",
    "    lst=[] # create a list to store characters which exist in the dictionary, and using them to do further calculation.\n",
    "    for i in range(len(sen)): # for each character\n",
    "        if sen[i] in char_list:\n",
    "            index=char_list.index(sen[i]) # 返回元素所在位置\n",
    "            lst.append(stroke_list[index])\n",
    "    total_stroke=0\n",
    "    for j in range(len(lst)):\n",
    "        total_stroke+=int(lst[j])\n",
    "    try:\n",
    "        stroke_score=total_stroke/(len(lst))\n",
    "        return stroke_score\n",
    "    except:\n",
    "        return 0\n",
    "            \n",
    "infile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 汉字熟悉度，返回sentence平均字频（最大值4.8867,最小值0）\n",
    "\n",
    "# infile2=open('../data/现代汉语常用字表（常用词分级）.csv','r',encoding='utf-8')\n",
    "infile3=open('../data/现代汉语语料库汉字频率表.csv','r',encoding='utf-8')\n",
    "\n",
    "# to_read2=csv.reader(infile2)\n",
    "# lst2=[]\n",
    "# for row in to_read2:\n",
    "#     lst2.append(row) # a list of characters and their strokes\n",
    "\n",
    "# char_list2=[]\n",
    "# level_list2=[]\n",
    "# for i in range(len(lst2)):\n",
    "#     char_list2.append(lst2[i][0])\n",
    "#     level_list2.append(lst2[i][1])\n",
    "\n",
    "to_read3=csv.reader(infile3)\n",
    "lst3=[]\n",
    "for row in to_read3:\n",
    "    lst3.append(row) # a list of characters and their strokes\n",
    "\n",
    "old_str2=lst3[0][0]\n",
    "new_str2=old_str2[-1]\n",
    "lst3[0][0]=new_str2\n",
    "    \n",
    "char_list3=[]\n",
    "freq_list3=[]\n",
    "for i in range(len(lst3)):\n",
    "    char_list3.append(lst3[i][0])\n",
    "    freq_list3.append(lst3[i][1])\n",
    "    \n",
    "# def familiar_score(sen,char_list2,char_list3,level_list2,freq_list3):\n",
    "def familiar_score(sen,char_list3,freq_list3):\n",
    "    lst2=[] # to store frequency score\n",
    "    for i in range(len(sen)): # for each character\n",
    "        if sen[i] in char_list3:\n",
    "            index=char_list3.index(sen[i]) # 返回元素所在位置\n",
    "            freq=freq_list3[index]\n",
    "            lst2.append(float(freq))\n",
    "#             log_freq=math.log(float(freq))\n",
    "#             lst2.append(log_freq)\n",
    "    freq_score=np.mean(lst2)\n",
    "    if len(lst2)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return freq_score\n",
    "    \n",
    "\n",
    "\n",
    "# infile2.close()\n",
    "infile3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# familiar_score(sen,char_list3,freq_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 汉字多样性，返回类符-形符比值（最大值1，最小值0）\n",
    "def variability_score(sen):\n",
    "    lst=[]\n",
    "    for item in psg.lcut(sen):\n",
    "        lst.append([item.word,item.flag])\n",
    "    word_amt=len(lst)\n",
    "    flag_lst=[]\n",
    "    for i in range(len(lst)):\n",
    "        flag_lst.append(lst[i][1])\n",
    "    dic={}\n",
    "    for i in flag_lst:\n",
    "        dic[i]=dic.get(i,0)+1\n",
    "    keys_lst=dic.keys()\n",
    "    flag_amt=len(keys_lst)\n",
    "    ttr_score=flag_amt/word_amt\n",
    "    return ttr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variability_score(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 综合前三项得到最后的readability score，权重占比直接取自文献中预测比重（再将其标准化到0-100区间）\n",
    "\n",
    "def readability_score(sen,char_list,stroke_list,char_list3,freq_list3):\n",
    "    complex_score=stroke_complexity_score(sen,char_list,stroke_list)\n",
    "    fam_score=familiar_score(sen,char_list3,freq_list3)\n",
    "    var_score=variability_score(sen)\n",
    "    score=0.42*fam_score-0.17*complex_score-0.41*var_score\n",
    "    score_std=((score+6.53)/(1.71+6.53))*100\n",
    "    return score_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readability_score(sen,char_list1,stroke_list1,char_list3,freq_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 5 将所有标题计算readability score并输出\n",
    "\n",
    "# with open('../data/bilibili_food_perfect5000.csv','r',encoding='utf-8')as infile:\n",
    "#     rows=csv.reader(infile)\n",
    "#     info_lst=[]\n",
    "#     for row in rows:\n",
    "#         info_lst.append(row)\n",
    "#     x=info_lst.pop(0)\n",
    "\n",
    "# with open('../data/bilibili_food_perfect5000_addscore.csv','w',newline='')as outfile:\n",
    "#     to_write=csv.writer(outfile)\n",
    "# #     to_write.writerow(['link','title','view','danmu','author','url','publish','like','toujinbi','collect','repost','follower','readability_score'])\n",
    "#     score_lst=[]\n",
    "#     for items in info_lst:\n",
    "#         score=readability_score(items[1],char_list1,stroke_list1,char_list3,freq_list3)\n",
    "# #         score=str(score)\n",
    "#         score_lst.append([score])\n",
    "# #         items.append(score)\n",
    "#     to_write.writerows(score_lst)\n",
    "# #             to_write.writerow(items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
